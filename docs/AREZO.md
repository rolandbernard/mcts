
# AlphaZero algorithm

This document gives an explanation for the AlphaZero algorithm.

## Basic architecture


## Model architecture


## Search algorithm

### PUCB formula


## Self-Play


## Training


## MuZero sketch


## References

<b id="f1">(1)</b> Silver, David, et al. "Mastering the game of Go with deep neural networks and tree search." nature
529.7587 (2016): 484-489.

<b id="f2">(2)</b> Auer, Peter, Nicolo Cesa-Bianchi, and Paul Fischer. "Finite-time analysis of the
multiarmed bandit problem." Machine learning 47 (2002): 235-256

<b id="f3">(3)</b> Kocsis, Levente, and Csaba Szepesv√°ri. "Bandit based monte-carlo planning." Machine Learning: ECML
2006: 17th European Conference on Machine Learning Berlin, Germany, September 18-22, 2006
Proceedings 17. Springer Berlin Heidelberg, 2006.

<b id="f4">(4)</b> Rosin, Christopher D. "Multi-armed bandits with episode context." Annals of Mathematics and
Artificial Intelligence 61.3 (2011): 203-230.

<b id="f5">(5)</b> Silver, David, et al. "Mastering the game of go without human knowledge." nature 550.7676 (2017):
354-359.

<b id="f6">(6)</b> Silver, David, et al. "Mastering chess and shogi by self-play with a general reinforcement
learning algorithm." arXiv preprint arXiv:1712.01815 (2017).

<!-- <b id="f6">(6)</b> Schrittwieser, Julian, et al. "Mastering atari, go, chess and shogi by planning with a learned
model." Nature 588.7839 (2020): 604-609. -->
